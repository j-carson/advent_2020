{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from ast import literal_eval\n",
    "from collections import  namedtuple\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Essentially token types\n",
    "Choice = namedtuple(\"Choice\", \"s\")\n",
    "Sequence = namedtuple(\"Sequence\", \"s\")\n",
    "Constant = namedtuple(\"Constant\", \"s\")\n",
    "SubRule = namedtuple(\"SubRule\", \"s\")\n",
    "\n",
    "def read_rules(text_rules, problem_number=1):\n",
    "    \n",
    "    patterns = {}\n",
    "    unsolved = {}\n",
    "    \n",
    "    def make_sequence(chunk):\n",
    "        \"A sequence of one item is collapsed to a sub-rule\"\n",
    "        words = chunk.split()\n",
    "        if len(words) == 1:\n",
    "            sub_rule = int(words[0])\n",
    "            if sub_rule in unsolved:\n",
    "                return unsolved[sub_rule].copy(deep=True)\n",
    "            return SubRule(int(words[0]))\n",
    "        else:\n",
    "            return Sequence([SubRule(int(w)) for w in words])\n",
    "    \n",
    "    for line in text_rules.splitlines():\n",
    "        ruleid, ruledata = line.split(\":\")\n",
    "        ruleid = int(ruleid)\n",
    "        \n",
    "        if '\"' in ruledata:\n",
    "            patterns[ruleid] = Constant(literal_eval(ruledata.strip()))\n",
    "            \n",
    "        elif \"|\" in ruledata:\n",
    "            chunks = ruledata.split(\"|\")\n",
    "            subrules = [ make_sequence(chunk) for chunk in chunks ] \n",
    "            unsolved[ruleid] = Choice(subrules)\n",
    "            \n",
    "        else: \n",
    "            unsolved[ruleid] = make_sequence(ruledata)\n",
    "            \n",
    "    def resolver(item):\n",
    "        if type(item) is Constant:\n",
    "            return item\n",
    "        elif type(item) is Sequence:\n",
    "            assert len(item.s) > 1\n",
    "            return Sequence([resolver(ii) for ii in item.s])\n",
    "        elif type(item) is Choice:\n",
    "            assert len(item.s) == 2\n",
    "            return Choice([resolver(ii) for ii in item.s])\n",
    "        elif type(item) is SubRule:\n",
    "            return patterns[item.s]\n",
    "        else:\n",
    "            raise TypeError(f\"What the heck??? {item} {type(item)}\")\n",
    "    \n",
    "    while len(unsolved):\n",
    "        for key, value in unsolved.copy().items():\n",
    "            try:\n",
    "                if type(value) is SubRule:\n",
    "                    patterns[key] = resolver(patterns[value.s])\n",
    "                else:\n",
    "                    patterns[key] = resolver(value)\n",
    "                unsolved.pop(key)\n",
    "            except KeyError:\n",
    "                    pass\n",
    "                \n",
    "    return patterns\n",
    "\n",
    "def yield_pattern(rule):\n",
    "    if type(rule) is Constant:\n",
    "        yield rule.s\n",
    "        \n",
    "    elif type(rule) is Choice:\n",
    "        yield from yield_pattern(rule.s[0])\n",
    "        yield from yield_pattern(rule.s[1])\n",
    "        \n",
    "    elif type(rule) is Sequence:\n",
    "        iterators = (yield_pattern(item) for item in rule.s)\n",
    "        for parts in product(*iterators):\n",
    "            yield \"\".join(parts)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Huh, interesting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Path(\"rules.txt\").read_text()\n",
    "ruledata, imagedata = data.split(\"\\n\\n\")\n",
    "my_rules = read_rules(ruledata)\n",
    "valid_patterns = set(yield_pattern(my_rules[0]))\n",
    "\n",
    "match = sum([line in valid_patterns for line in imagedata.splitlines() ])\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaaabb', 'aaabab', 'abbabb', 'abbbab', 'aabaab', 'aabbbb', 'abaaab', 'ababbb']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "example_rules = '''0: 4 1 5\n",
    "1: 2 3 | 3 2\n",
    "2: 4 4 | 5 5\n",
    "3: 4 5 | 5 4\n",
    "4: \"a\"\n",
    "5: \"b\"'''\n",
    "example_data = '''ababbb\n",
    "bababa\n",
    "abbbab\n",
    "aaabbb\n",
    "aaaabbb'''\n",
    "\n",
    "example_rules = read_rules(example_rules)\n",
    "matching_patterns = list(yield_pattern(example_rules[0]))\n",
    "print(matching_patterns) # should be 8 in the toy example\n",
    "\n",
    "test = 0\n",
    "for line in example_data.splitlines():\n",
    "    for pat in matching_patterns:\n",
    "        if line == pat:\n",
    "            test += 1\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
